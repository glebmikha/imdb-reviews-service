{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/aclimdb/\"\n",
    "\n",
    "ff = [path + \"train/pos/\" + x for x in os.listdir(path + \"train/pos\")] + \\\n",
    "     [path + \"train/neg/\" + x for x in os.listdir(path + \"train/neg\")] + \\\n",
    "     [path + \"test/pos/\" + x for x in os.listdir(path + \"test/pos\")] + \\\n",
    "     [path + \"test/neg/\" + x for x in os.listdir(path + \"test/neg\")]\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "    \n",
    "input_label = ([1] * 12500 + [0] * 12500) * 2\n",
    "input_text  = []\n",
    "\n",
    "for f in ff:\n",
    "    with open(f) as fin:\n",
    "        pass\n",
    "        input_text += [remove_tags(\" \".join(fin.readlines()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "max_len = 400\n",
    "tok = Tokenizer(num_words)\n",
    "tok.fit_on_texts(input_text[:25000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tok.texts_to_sequences(input_text[:25000])\n",
    "X_test  = tok.texts_to_sequences(input_text[25000:])\n",
    "y_train = input_label[:25000]\n",
    "y_test  = input_label[25000:]\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test  = sequence.pad_sequences(X_test,  maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 300, input_length=max_len))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(GRU(16,activation='relu'))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 274s 11ms/step - loss: 0.5322 - acc: 0.7294 - val_loss: 0.2926 - val_acc: 0.8758\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 0.2687 - acc: 0.8914 - val_loss: 0.2852 - val_acc: 0.8838\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 263s 11ms/step - loss: 0.2152 - acc: 0.9174 - val_loss: 0.2458 - val_acc: 0.8998\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.1839 - acc: 0.9304 - val_loss: 0.3089 - val_acc: 0.8860\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.1628 - acc: 0.9394 - val_loss: 0.2572 - val_acc: 0.8988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f460d955978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, nb_epoch=5, verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_imdb.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
